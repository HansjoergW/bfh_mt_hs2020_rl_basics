{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# stellt sicher, dass beim verÃ¤ndern der core library diese wieder neu geladen wird\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bfh_mt_hs2020_rl_basics.env import CarEnv\n",
    "\n",
    "import gym\n",
    "import ptan\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from bfh_mt_hs2020_rl_basics.env import CarEnv\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Iterable, Tuple, List\n",
    "\n",
    "import torch\n",
    "\n",
    "class AgentBase(ABC):\n",
    "    \n",
    "    def __init__(self, env: CarEnv, devicestr:str):\n",
    "        self.env = env\n",
    "        self.device = torch.device(devicestr)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_net(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_tgtnet(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_buffer(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def iteration_completed(self, iteration: int):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SimpleAgent has no special improvements concering training stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from bfh_mt_hs2020_rl_basics.env import CarEnv\n",
    "\n",
    "import gym\n",
    "import ptan\n",
    "import torch\n",
    "from torch import device\n",
    "\n",
    "class SimpleAgent(AgentBase):\n",
    "    \n",
    "    def __init__(self, env: CarEnv, \n",
    "                 devicestr:str,  \n",
    "                 gamma:float, \n",
    "                 buffer_size:int, \n",
    "                 target_net_sync:int = 1000, \n",
    "                 eps_start:float = 1.0, \n",
    "                 eps_final:float = 0.02, \n",
    "                 eps_frames:int = 10**5):\n",
    "        \n",
    "        super(SimpleAgent, self).__init__(env, devicestr)\n",
    "\n",
    "        self.target_net_sync = target_net_sync\n",
    "        \n",
    "        self.net = self._config_net()\n",
    "        \n",
    "        self.tgt_net = ptan.agent.TargetNet(self.net)\n",
    "        \n",
    "        self.selector = ptan.actions.EpsilonGreedyActionSelector(\n",
    "                                    epsilon=1, \n",
    "                                    selector=ptan.actions.ArgmaxActionSelector())\n",
    "        \n",
    "        self.epsilon_tracker = ptan.actions.EpsilonTracker(selector=self.selector, eps_start=eps_start, eps_final=eps_final, eps_frames=eps_frames)\n",
    "\n",
    "        self.agent = agent = ptan.agent.DQNAgent(self.net, self.selector, device = self.device)\n",
    "        \n",
    "        self.exp_source = ptan.experience.ExperienceSourceFirstLast(self.env, self.agent, gamma=gamma)\n",
    "        self.buffer = ptan.experience.ExperienceReplayBuffer(self.exp_source, buffer_size=buffer_size)\n",
    "        \n",
    "\n",
    "    def _config_net(self)-> nn.Module:\n",
    "        return SimpleNet(self.env.observation_space.shape[0], 128, self.env.action_space.n).to(self.device)\n",
    "    \n",
    "    \n",
    "    def iteration_completed(self, iteration: int):\n",
    "        \n",
    "        self.epsilon_tracker.frame(iteration)\n",
    "        \n",
    "        if iteration % self.target_net_sync == 0:\n",
    "            self.tgt_net.sync()\n",
    "\n",
    "    def get_net(self):\n",
    "        return self.net\n",
    "    \n",
    "    def get_tgtnet(self):\n",
    "        return self.tgt_net\n",
    "    \n",
    "    def get_buffer(self):\n",
    "        return self.buffer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA = 0.9\n",
    "REPLAY_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simpleagent_cpu():\n",
    "    print(\"test cpu\")\n",
    "    env = CarEnv()\n",
    "    agent = SimpleAgent(env, \"cpu\", gamma=GAMMA, buffer_size=REPLAY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simpleagent_cuda():\n",
    "    print(\"test cuda\")\n",
    "    env = CarEnv()\n",
    "    agent = SimpleAgent(env, \"cuda\", gamma=GAMMA, buffer_size=REPLAY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test cpu\n",
      "test cuda\n"
     ]
    }
   ],
   "source": [
    "test_simpleagent_cpu()\n",
    "test_simpleagent_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rainbow Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RainbowAgent combines several measures that should increase the stability of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.nn as nn\n",
    "\n",
    "class DuelingNet(nn.Module):\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(DuelingNet, self).__init__()\n",
    "        \n",
    "        self.net_adv = nn.Sequential(\n",
    "            nn.NoisyLinear(obs_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.NoisyLinear(hidden_size, n_actions)\n",
    "        )\n",
    "        \n",
    "        self.net_val = nn.Sequential(\n",
    "            nn.NoisyLinear(obs_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.NoisyLinear(hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        val = self.net_val(x.float())\n",
    "        adv = self.net_adv(x.float())\n",
    "    \n",
    "        return val + (adv - adv.mean(dim=1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from bfh_mt_hs2020_rl_basics.env import CarEnv\n",
    "\n",
    "import gym\n",
    "import ptan\n",
    "import torch\n",
    "from torch import device\n",
    "\n",
    "class RainbowAgent(AgentBase):\n",
    "    \n",
    "    def __init__(self, env: CarEnv, \n",
    "                 devicestr:str,  \n",
    "                 gamma:float, \n",
    "                 buffer_size:int, \n",
    "                 target_net_sync:int = 1000,\n",
    "                 steps_count:int = 3,\n",
    "                 prio_replay_alpha:float = 0.6):\n",
    "        \n",
    "        self.env = env\n",
    "        self.steps_count = steps_count\n",
    "        self.device = torch.device(devicestr)\n",
    "        self.target_net_sync = target_net_sync\n",
    "        \n",
    "        self.net = self._config_net()\n",
    "        \n",
    "        self.tgt_net = ptan.agent.TargetNet(self.net)\n",
    "        \n",
    "        self.selector = ptan.actions.ArgmaxActionSelector()\n",
    "        \n",
    "        self.agent = agent = ptan.agent.DQNAgent(self.net, self.selector, device = self.device)\n",
    "        \n",
    "        self.exp_source = ptan.experience.ExperienceSourceFirstLast(self.env, self.agent, gamma=gamma, steps_count=self.steps_count)\n",
    "        \n",
    "        self.buffer = ptan.experience.PrioritizedReplayBuffer(self.exp_source, buffer_size=buffer_size, alpha=prio_replay_alpha)\n",
    "        \n",
    "\n",
    "    def _config_net(self)-> nn.Module:\n",
    "        return DuelingNet(self.env.observation_space.shape[0], 128, self.env.action_space.n).to(self.device)\n",
    "\n",
    "\n",
    "    def iteration_completed(self, iteration: int):\n",
    "        \n",
    "        if iteration % self.target_net_sync == 0:\n",
    "            self.tgt_net.sync()\n",
    "\n",
    "\n",
    "    def get_net(self):\n",
    "        return self.net\n",
    "\n",
    "\n",
    "    def get_tgtnet(self):\n",
    "        return self.tgt_net\n",
    "\n",
    "\n",
    "    def get_buffer(self):\n",
    "        return self.buffer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
