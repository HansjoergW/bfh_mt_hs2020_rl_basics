{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# stellt sicher, dass beim verÃ¤ndern der core library diese wieder neu geladen wird\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from bfh_mt_hs2020_rl_basics.agent import Agent\n",
    "\n",
    "from typing import Iterable, Tuple, List\n",
    "import numpy as np\n",
    "\n",
    "from ignite.engine import Engine\n",
    "\n",
    "from ptan.experience import ExperienceFirstLast\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer, Adam\n",
    "from torch import device\n",
    "\n",
    "\n",
    "class Bridge:\n",
    "    \n",
    "    def __init__(self, agent: Agent, device: device, optimizer: Optimizer = None, \n",
    "                 learning_rate: float = 0.0001, \n",
    "                 gamma: float = 0.9, \n",
    "                 initial_population: int = 1000, \n",
    "                 batch_size: int = 32):\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.initial_population = initial_population\n",
    "        self.batch_size = batch_size\n",
    "                \n",
    "        self.device = device    \n",
    "        self.agent = agent\n",
    "        \n",
    "        if optimizer is not None:\n",
    "            self.optimzer = optimizer\n",
    "        else:\n",
    "            self.optimizer = Adam(self.agent.net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "    def batch_generator(self):\n",
    "        self.agent.buffer.populate(self.initial)\n",
    "        while True:\n",
    "            self.agent.buffer.populate(1)\n",
    "            yield self.agent.buffer.sample(self.batch_size)\n",
    "\n",
    "\n",
    "    def process_batch(self, engine:Engine, batch: List[ExperienceFirstLast]):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss_v = self._calc_loss(batch)\n",
    "\n",
    "        loss_v.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        self.agent.iteration_completed(engine.state.iteration)\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss_v.item(),\n",
    "            \"epsilon\": self.agent.selector.epsilon,\n",
    "        }\n",
    "\n",
    "\n",
    "    def _calc_loss(self, batch: List[ExperienceFirstLast]):\n",
    "        \n",
    "        states, actions, rewards, dones, next_states = self._unpack_batch(batch)\n",
    "\n",
    "        states_v      = torch.tensor(states).to(self.device)\n",
    "        next_states_v = torch.tensor(next_states).to(self.device)\n",
    "        actions_v     = torch.tensor(actions).to(self.device)\n",
    "        rewards_v     = torch.tensor(rewards).to(self.device)\n",
    "        done_mask     = torch.BoolTensor(dones).to(self.device)\n",
    "\n",
    "        actions_v         = actions_v.unsqueeze(-1)\n",
    "        state_action_vals = self.agent.net(states_v).gather(1, actions_v)\n",
    "        state_action_vals = state_action_vals.squeeze(-1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            next_state_vals            = self.agent.tgt_net.target_model(next_states_v).max(1)[0]\n",
    "            next_state_vals[done_mask] = 0.0\n",
    "    \n",
    "        bellman_vals = next_state_vals.detach() * self.gamma + rewards_v\n",
    "        return nn.MSELoss()(state_action_vals, bellman_vals)\n",
    "\n",
    "\n",
    "    def _unpack_batch(self, batch: List[ExperienceFirstLast]):\n",
    "        states, actions, rewards, dones, last_states = [],[],[],[],[]\n",
    "        \n",
    "        for exp in batch:\n",
    "            state = np.array(exp.state)\n",
    "            states.append(state)\n",
    "            actions.append(exp.action)\n",
    "            rewards.append(exp.reward)\n",
    "            dones.append(exp.last_state is None)\n",
    "            \n",
    "            if exp.last_state is None:\n",
    "                lstate = state  # the result will be masked anyway\n",
    "            else:\n",
    "                lstate = np.array(exp.last_state)\n",
    "            last_states.append(lstate)\n",
    "            \n",
    "        return np.array(states, copy=False), \\\n",
    "               np.array(actions), \\\n",
    "               np.array(rewards, dtype=np.float32), \\\n",
    "               np.array(dones,   dtype=np.uint8), \\\n",
    "               np.array(last_states, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bfh_mt_hs2020_rl_basics.agent import Agent\n",
    "from bfh_mt_hs2020_rl_basics.env import CarEnv\n",
    "\n",
    "def basic_init() -> Bridge:\n",
    "    env = CarEnv()\n",
    "    agent = Agent(env, gamma=0.9, buffer_size=1000)\n",
    "    bridge = Bridge(agent, torch.device(\"cpu\"), gamma=0.9)\n",
    "    \n",
    "    return bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_experiences() -> List[ExperienceFirstLast]:\n",
    "    return [\n",
    "        ExperienceFirstLast( np.array([0.0, 0.0, 0.0], dtype=np.float32), np.int64(0), 1.0,  np.array([0.5, 0.5, 0.5], dtype=np.float32)),\n",
    "        ExperienceFirstLast( np.array([1.0, 1.0, 1.0], dtype=np.float32), np.int64(1), 2.0,  None)        \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_init():\n",
    "    assert basic_init() != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_unpack():\n",
    "    bridge = basic_init()\n",
    "    batch = simple_experiences()\n",
    "    unpacked = bridge._unpack_batch(batch)\n",
    "    # todo -Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_calc_loss():\n",
    "    bridge = basic_init()\n",
    "    batch = simple_experiences()\n",
    "    loss = bridge._calc_loss(batch)\n",
    "    # todo -Checks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine\n",
    "\n",
    "def test_process_batch():\n",
    "    bridge = basic_init()\n",
    "    batch = simple_experiences()\n",
    "    bridge.process_batch(Engine(bridge.process_batch), batch)\n",
    "    # todo -Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basis Tests\n",
    "test_init()\n",
    "test_unpack()\n",
    "test_calc_loss()\n",
    "test_process_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
