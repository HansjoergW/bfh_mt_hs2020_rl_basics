{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# stellt sicher, dass beim verändern der core library diese wieder neu geladen wird\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from bfh_mt_hs2020_rl_basics.agent import Agent\n",
    "\n",
    "from typing import Iterable, Tuple, List\n",
    "import numpy as np\n",
    "\n",
    "from ignite.engine import Engine\n",
    "\n",
    "from ptan.experience import ExperienceFirstLast\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer, Adam\n",
    "from torch import device\n",
    "\n",
    "class Bridge:\n",
    "    \n",
    "    def __init__(self, agent: Agent, device: device, optimizer: Optimizer = None, \n",
    "                 learning_rate: float = 0.0001, gamma: float =0.9, target_net_sync: int = 1000):\n",
    "        self.gamma = gamma\n",
    "        self.target_net_sync = target_net_sync\n",
    "        \n",
    "        self.device = device    \n",
    "        self.agent = agent\n",
    "        \n",
    "        if optimizer is not None:\n",
    "            self.optimzer = optimizer\n",
    "        else:\n",
    "            self.optimizer = Adam(self.agent.net.parameters(), lr=learning_rate)\n",
    "\n",
    "        \n",
    "    def process_batch(self, engine:Engine, batch: List[ExperienceFirstLast]):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss_v = self._calc_loss(batch)\n",
    "\n",
    "        loss_v.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        \n",
    "        entweder eigener Listener, der called oder hier heraus ein call zu Agent\n",
    "        Man könnte eigentlich auf Iteration completed reagieren\n",
    "        Bei der Initialisierung könnte man engine mitgeben und dann könnte man sich direkt hier registieren..\n",
    "        Problem ist aber, das Engine den Parameter process_batch bei der Initialisierung benötigt\n",
    "        \n",
    "        wie auch immer, im Agent sollte eine itereation completed Methode vorhanden sein.\n",
    "        das gehört nicht hier hin.. \n",
    "        \n",
    "        epsilon_tracker.frame(engine.state.iteration)\n",
    "        \n",
    "        if engine.state.iteration % self.target_net_sync == 0:\n",
    "            self.tgt_net.sync()\n",
    "\n",
    "        return {\n",
    "            \"loss\": loss_v.item(),\n",
    "            \"epsilon\": selector.epsilon,\n",
    "        }\n",
    "\n",
    "\n",
    "    def _calc_loss(self, batch: List[ExperienceFirstLast]):\n",
    "        \n",
    "        states, actions, rewards, dones, next_states = self._unpack_batch(batch)\n",
    "\n",
    "        states_v      = torch.tensor(states).to(self.device)\n",
    "        next_states_v = torch.tensor(next_states).to(self.device)\n",
    "        actions_v     = torch.tensor(actions).to(self.device)\n",
    "        rewards_v     = torch.tensor(rewards).to(self.device)\n",
    "        done_mask     = torch.BoolTensor(dones).to(self.device)\n",
    "\n",
    "        actions_v         = actions_v.unsqueeze(-1)\n",
    "        state_action_vals = self.agent.net(states_v).gather(1, actions_v)\n",
    "        state_action_vals = state_action_vals.squeeze(-1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            next_state_vals            = self.agent.tgt_net.target_model(next_states_v).max(1)[0]\n",
    "            next_state_vals[done_mask] = 0.0\n",
    "    \n",
    "        bellman_vals = next_state_vals.detach() * self.gamma + rewards_v\n",
    "        return nn.MSELoss()(state_action_vals, bellman_vals)\n",
    "\n",
    "\n",
    "    def _unpack_batch(self, batch: List[ExperienceFirstLast]):\n",
    "        states, actions, rewards, dones, last_states = [],[],[],[],[]\n",
    "        \n",
    "        for exp in batch:\n",
    "            state = np.array(exp.state)\n",
    "            states.append(state)\n",
    "            actions.append(exp.action)\n",
    "            rewards.append(exp.reward)\n",
    "            dones.append(exp.last_state is None)\n",
    "            \n",
    "            if exp.last_state is None:\n",
    "                lstate = state  # the result will be masked anyway\n",
    "            else:\n",
    "                lstate = np.array(exp.last_state)\n",
    "            last_states.append(lstate)\n",
    "            \n",
    "        return np.array(states, copy=False), \\\n",
    "               np.array(actions), \\\n",
    "               np.array(rewards, dtype=np.float32), \\\n",
    "               np.array(dones,   dtype=np.uint8), \\\n",
    "               np.array(last_states, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bfh_mt_hs2020_rl_basics.agent import Agent\n",
    "from bfh_mt_hs2020_rl_basics.env import CarEnv\n",
    "\n",
    "def basic_init() -> Bridge:\n",
    "    env = CarEnv()\n",
    "    agent = Agent(env, gamma=0.9, buffer_size=1000)\n",
    "    bridge = Bridge(agent, torch.device(\"cpu\"), gamma=0.9, target_net_sync=1000)\n",
    "    \n",
    "    return bridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_experiences() -> List[ExperienceFirstLast]:\n",
    "    return [\n",
    "        ExperienceFirstLast( np.array([0.0, 0.0, 0.0], dtype=np.float32), np.int64(0), 1.0,  np.array([0.0, 0.0, 0.0], dtype=np.float32)),\n",
    "        ExperienceFirstLast( np.array([0.0, 0.0, 0.0], dtype=np.float32), np.int64(0), 2.0,  np.array([0.0, 0.0, 0.0], dtype=np.float32))        \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_init():\n",
    "    assert basic_init() != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_unpack():\n",
    "    bridge = basic_init()\n",
    "    batch = simple_experiences()\n",
    "    unpacked = bridge._unpack_batch(batch)\n",
    "    # todo -Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_calc_loss():\n",
    "    bridge = basic_init()\n",
    "    batch = simple_experiences()\n",
    "    loss = bridge._calc_loss(batch)\n",
    "    print(loss)\n",
    "    # todo -Checks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine\n",
    "\n",
    "def test_process_batch():\n",
    "    bridge = basic_init()\n",
    "    batch = simple_experiences()\n",
    "    bridge.process_batch(Engine(bridge.process_batch), batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epsilon_tracker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-1ecb17aa3872>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_process_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-75-cfe855aa96c9>\u001b[0m in \u001b[0;36mtest_process_batch\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mbridge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbasic_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimple_experiences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mbridge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEngine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbridge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-69-3acf45db1e10>\u001b[0m in \u001b[0;36mprocess_batch\u001b[1;34m(self, engine, batch)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mloss_v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mepsilon_tracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_net_sync\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epsilon_tracker' is not defined"
     ]
    }
   ],
   "source": [
    "test_process_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_init()\n",
    "test_unpack()\n",
    "test_calc_loss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
